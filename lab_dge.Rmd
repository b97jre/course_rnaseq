---
title: "DGE Workflow"
subtitle: "Workshop on RNA-Seq"
author: "`r paste0('<b>Roy Francis</b> | ',format(Sys.time(), '%d-%b-%Y'))`"
output:
  bookdown::html_document2:
          toc: true
          toc_float: true
          toc_depth: 4
          number_sections: true
          theme: flatly
          highlight: tango
          df_print: default
          code_folding: "none"
          self_contained: false
          keep_md: false
          encoding: 'UTF-8'
          css: "assets/lab.css"
---

```{r,child="assets/header-lab.Rmd"}
```

```{r,include=FALSE}
# data handling
library(dplyr)
#library(tidyr)
#library(stringr)

# plotting
library(ggplot2)

library(biomaRt) # annotation
library(DESeq2) # rna-seq
library(edgeR) # rna-seq
```

# Data preprocessing

Data preprocessing is done in R. First, we read in the count table.

```{r}
cr <- read.table("./data/count_raw.txt",header=TRUE)
head(cr)
str(cr)
```

The count data shows read counts across samples and genes. The columns denote samples and rows denote genes.

Read in the metadata. Each row corresponds to a sample. The sample names can be added as row names.

```{r}
mr <- read.csv2("./data/metadata_raw.csv",header=TRUE,stringsAsFactors=F)
rownames(mr) <- mr$Sample_ID
head(mr)
str(mr)
```

The metadata columns are sample name and timepoints. It is a good idea to check that the number of columns of data match the number of rows of metadata. The column names of data must also match the rownames of metadata.

```{r}
all.equal(colnames(cr),rownames(mr))
```

Let's create a boxplot to visualise the distibution of counts.

```{r}
boxplot(log10(as.matrix(cr)+1),ylab=expression('Log'[10]~'Read counts'),las=2,
        main="Raw data")
```

The median values are zero across all samples. This is a sign that the dataset would benefit from a low count filtering.

We can check if any samples need to be discarded based on the number of genes detected. We create a barplot of genes detected across samples.

```{r}
{barplot(colSums(cr>5),ylab="Number of detected genes",las=2)
abline(h=median(colSums(cr>5)))}
```

None of the samples look bad enough to be removed. And we can create a similar plot for detection rate across genes.

```{r}
{barplot(rowSums(cr>5),xlab="Genes",ylab="Number of samples",las=2,names.arg="")
abline(h=median(rowSums(cr>5)))}
```

Some of the genes are not detected across most samples. These genes can be discarded.

```{r}
# remove genes with low counts
keepgenes <- rowSums(cr>5)>(0.60*ncol(cr))
cf <- cr[keepgenes,]
```

```{r}
boxplot(log10(as.matrix(cf)+1),ylab=expression('Log'[10]~'Read counts'),las=2,
        main="Filtered data")
```

The missingness in the dataset is reduced. The filtering process has removed `r nrow(cr)-nrow(cf)` genes with low counts. 

Since no samples were discarded, the metadata file will remain the same. And we can check that the labels are the same order in counts and metadata.

```{r}
all.equal(colnames(cf),rownames(mr))
```

At this point, we can save the filtered data.

```{r}
write.table(cf,"./data/counts_filtered.txt",col.names=T,quote=F,sep="\t",dec=".")
```

# Normalisation

The raw count data needs to be corrected for various biases before statistical inference. If the dataset is to be used in an R package for differential gene expression such as **DESeq2**, **edgeR** or **Limma**, the raw data must be used directly. This is because, these packages handle the correction and transformation internally.

## CPM/TPM

For analysis other than DGE, the dataset must be corrected before use. The most basic correction required is sequencing depth. This is achieved using rescaling the counts to counts per million.

We read in out filtered count data and metadata. We can use the function `cpm()` from R package **edgeR** for this.

```{r}
cf <- read.table("./data/counts_filtered.txt",header=TRUE)
mr <- read.csv2("./data/metadata_raw.csv",header=TRUE,stringsAsFactors=F)
rownames(mr) <- mr$Sample_ID
```

```{r}
cc <- edgeR::cpm(cf)
boxplot(log10(as.matrix(cc)+1),ylab=expression('Log'[10]~'Read counts'),las=2,main="CPM")
```

But, CPM data has some drawbacks. It is not suitable for within-sample comparisons. The total number of reads per sample varies from sample to sample. This also makes it harder to compare one experiment to another. In addition, gene length is not controlled for in this correction. RPKM/FPKM normalisations correct for gene length, but they are not recommended because they are not comparable between samples.

A better correction method that resolves these issues is TPM (transcripts-per-million). The code for computing TPM is simple.

```{r}
#' @title Compute TPM from a read count matrix
#' @param counts A numeric data.frame of read counts with samples (columns) and genes (rows).
#' @param len A vector of gene cds length equal to number of rows of dfr.
#'
#' https://support.bioconductor.org/p/91218/
#'
tpm <- function(counts,len) {
  x <- counts/len
  return(t(t(x)*1e6/colSums(x)))
}
```

We read in the annotation data, remove duplicated ensembl IDs and compute gene lengths.

```{r}
g <- read.delim("./data/human_genes.txt",header=T,stringsAsFactors=F)
g <- g[!duplicated(g$ensembl_gene_id),]
g$len <- g$end_position-g$start_position
rownames(g) <- g$ensembl_gene_id
```

Next, we find shared genes between count data and annotation data and match their order.

```{r}
igenes <- intersect(rownames(cf),g$ensembl_gene_id)
g1 <- g[igenes,]
cf1 <- cf[igenes,]
all.equal(rownames(cf1),g1$ensembl_gene_id)
```
```{r}
ct <- tpm(cf1,g1$len)
boxplot(log10(as.matrix(ct)+1),ylab=expression('Log'[10]~'Read counts'),las=2,main="TPM")
```

## DESeq2

DESeq2 internally corrects counts for sequencing depth and RNA compositional bias using **Median of ratios** method. To run this method, we create a DESeq2 object using the count data and metadata.

```{r}
library(DESeq2)
mr$Time <- factor(mr$Time)
d <- DESeqDataSetFromMatrix(countData=cf,colData=mr,design=~Time)
d <- DESeq2::estimateSizeFactors(d,type="ratio")
cd <- counts(d,normalized=TRUE)
boxplot(log10(as.matrix(cd)+1),ylab=expression('Log'[10]~'Read counts'),las=2,main="DESeq2")
```

## VST

For the purpose of exploratory analysis such as MDS, PCA, clustering etc, VST (variance-stabilizing-transformation) is recommended. VST is also run using DESeq2. As in the previous step, a DESeq2 object is created.

```{r}
library(DESeq2)
mr$Time <- factor(mr$Time)
d <- DESeqDataSetFromMatrix(countData=cf,colData=mr,design=~Time)
d <- DESeq2::estimateSizeFactors(d,type="ratio")
d <- DESeq2::estimateDispersions(d)
cv <- as.data.frame(assay(varianceStabilizingTransformation(d,blind=T)),check.names=F)
write.table(cv,"./data/counts_vst.txt",sep="\t",dec=".",quote=FALSE)
boxplot(log10(as.matrix(cv)+1),ylab=expression('Log'[10]~'Read counts'),las=2,main="VST")
```

# Exploratory

We will use the variance stabilized counts (VST) from the previous step for all exploratory analyses.

```{r}
cv <- read.table("./data/counts_vst.txt",header=TRUE)
mr <- read.csv2("./data/metadata_raw.csv",header=TRUE,stringsAsFactors=F)
rownames(mr) <- mr$Sample_ID
```

## Correlation

It is a good idea to start by checking correlation between samples. RNA-Seq samples generally have very high correlation (R^2 > 0.9). R^2 values below 0.8 may be an indication of an outlier sample. Depending on other QC metric, these low correlation samples may be discarded from analyses.

We use the function `cor()` for computing sample-to-sample Spearman correlation. Note that the input matrix has genes as rows and samples as columns. This generates a sample-to-sample pairwise correlation matrix. This matrix can be plotted as a heatmap using the `pheatmap()` function from the **pheatmap** R package.

```{r,fig.height=5,fig.width=6}
dmat <- as.matrix(cor(cv,method="spearman"))

library(pheatmap)
pheatmap(dmat,border_color=NA,annotation_col=mr[,"Time",drop=F],
         annotation_row=mr[,"Time",drop=F],annotation_legend=T)
```

In the matrix, red colour denotes higher correlation (higher similarity) and blue denotes lower correlation (lower similarity). `pheatmap()` also hierarchically clusters rows and columns based on correlation values. The dendrograms show how samples cluster. Annotation colours denote **Time** groups. Notice that samples group by **Time**.

## PCA

To run PCA, we use the R function `prcomp()`. It takes in a matrix where samples are rows and variables are columns. Therefore, we transpose our count matrix using the function `t()`. The next line of code plots the variance explained by the top PCs.

```{r,fig.height=5,fig.width=5}
pcaobj <- prcomp(x=t(cv))
barplot(round(pcaobj$sdev^2/sum(pcaobj$sdev^2)*100,2),las=2,
        names.arg=colnames(pcaobj$x),ylab="% Variance explained",
        xlab="PCA principal components")
```

The first two principal components in total explain 85% (75%+10%) of the variance in the dataset. This means a scatterplot of PC1 vs PC2 can help to visualise the most important trend in the data. Then we merge the rotated data with the metadata and plot a scatterplot coloured by our variable of interest (Time).

```{r,fig.height=4,fig.width=4.5}
pcamat1 <- as.data.frame(pcaobj$x)
pcamat2 <- merge(pcamat1,mr,by=0)

ggplot(pcamat2,aes(PC1,PC2,colour=Time))+
  geom_point()+
  theme_bw()
```

Samples cluster by the **Time** variable as expected.

An alternative way to create a PCA plot is directly from the DESeq2 object using the DESeq2 function `plotPCA()`.

```{r}
plotPCA(varianceStabilizingTransformation(d),intgroup="Time")
```

## Clustering

For clustering, we create a sample-to-sample pairwise distance matrix (here we use euclidian distance). The rows and columns of this matrix is then hierarchically clustered. We use the function `dist()` to compute the distance. Note that for a sample-to-sample matrix, the rows need to be samples and columns should be genes. Therefore, we use the function `t()` to transpose our VST normalised count matrix.

```{r,fig.height=5,fig.width=6}
dmat <- as.matrix(dist(t(cv)))

library(pheatmap)
pheatmap(dmat,border_color=NA,annotation_col=mr[,"Time",drop=F],
         annotation_row=mr[,"Time",drop=F],annotation_legend=T)
```

Hierarchically clustered sample-to-sample euclidian distance matrix. Larger distances mean lower similarity and vice-versa. In the matrix, red colour denotes larger distance (lower similarity) and blue denotes small distance (higher similarity). Annotation colours denote **Time** groups. The dendrogram helps to visualise sample clustering. Notice that samples group by **Time**.

# DGE

For differential gene expression, we use the **DESeq2** package. We use the raw filtered counts and metadata.

```{r}
cf <- read.table("./data/counts_filtered.txt",header=TRUE)
mr <- read.csv2("./data/metadata_raw.csv",header=TRUE,stringsAsFactors=F)
rownames(mr) <- mr$Sample_ID
```

The data is converted to a DESeq2 object. The GLM model we use is simple since we only have one variable of interest `~Time`. 

If we had other covariates to control for, we would add them to the model like so `~var+Time`. The variable of interest appears in the end. This model means find differentially expressed genes between groups under 'time' variable while controlling for the effect of 'var'. Similarily, batch effects can be controlled by specifying them in the model `~batch+Time`.

```{r}
library(DESeq2)
mr$Time <- factor(mr$Time)
d <- DESeqDataSetFromMatrix(countData=cf,colData=mr,design=~Time)
```

## Size factors

The first step is estimating size factors. The data is normalised for sequencing depth and compositional bias as done for the VST step. DESeq2 uses a method called *median-of-ratios* for this step.

```{r,block.title=TRUE}
d <- DESeq2::estimateSizeFactors(d,type="ratio")
```

<div class="optional">
<b>Optional</b>

For those interested in the details of the *median-of-ratios* method, click below.

<p>
<button class="btn btn-sm btn-primary btn-collapse btn-collapse-optional collapsed type="button" data-toggle="collapse" data-target="#dge-size-factor" aria-expanded="false" aria-controls="dge-size-factor">
</button>
</p>
<div class="collapse" id="dge-size-factor">
<div class="card card-body">

This is a step-by-step guide to computing normalisation factors (size factors) using the *median-of-ratios* method.

1. The geometric mean is computed across all samples for each gene.

```{r,block.title=TRUE}
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}

gmean <- apply(cf,1,gm_mean)
head(gmean)
```

2. Read counts for each gene is divided by the geometric mean of that gene to create a ratio.

```{r,block.title=TRUE}
ratio <- cf/gmean
head(ratio)[,1:5]
```

3. The median ratio for each sample (across all genes) is taken as the size factor for that sample.

```{r,block.title=TRUE}
sf <- apply(ratio,2,median)
sf
```

We can verify that these values are correct by comparing with size factors generated by DESeq2.

```{r,block.title=TRUE}
# deseq2 size factors
sizeFactors(d)
```

The raw counts are divided by the size factor to yeild normalised read counts.

```{r,block.title=TRUE}
# custom
head(t(t(cf)/sf))[,1:5]
# deseq2
head(counts(d,normalized=TRUE))[,1:5]
```

</div>
</div>
</div>

## Gene dispersion

When it comes to comparing values between groups, some measure of variation is needed to estimate the variability in gene counts within groups. Dispersion is a measure of variation in a dataset. Variance and standard deviation are not a good measure to estimate variability because it correlates with the mean.

<div class="optional">
<b>Optional</b>

For some more discussion on dispersion, click below.

<p>
<button class="btn btn-sm btn-primary btn-collapse btn-collapse-optional collapsed type="button" data-toggle="collapse" data-target="#dge-dispersion" aria-expanded="false" aria-controls="dge-dispersion">
</button>
</p>
<div class="collapse" id="dge-dispersion">
<div class="card card-body">

We can create a mean counts vs variance plot for all genes in our dataset.

```{r,fig.height=4.5,fig.width=4.5,block.title=TRUE}
dm <- apply(cd,1,mean)
dv <- apply(cd,1,var)

ggplot(data.frame(mean=log10(dm+1),var=log10(dv+1)),
       aes(mean,var))+
  geom_point(alpha=0.2)+
  geom_smooth(method="lm")+
  labs(x=expression('Log'[10]~'Mean counts'),y=expression('Log'[10]~'Variance'))+
  theme_bw()
```

We see a mostly linear relationship on the log scale. The blue line denotes a linear fit. Genes that have larger read counts show higher variance. It's hard to say which genes are more variable based on this alone. Therefore, variance is not a good measure to identify variation in read counts. A measure that controls for this mean-variance relationship is what we need.

Lo and behold, the coefficient of variation (CV). 

```{r,fig.height=4.5,fig.width=4.5,block.title=TRUE}
cva <- function(x) sd(x)/mean(x)
dc <- apply(cd,1,cva)

ggplot(data.frame(mean=log10(dm+1),var=dc),
       aes(mean,var))+
  geom_point(alpha=0.2)+
  geom_smooth()+
  labs(x=expression('Log'[10]~'Mean counts'),y="Coefficient of variation")+
  theme_bw()
```

Now, we see that genes with lower counts have higher variability and genes with larger counts have lower variability. A measure like CV is taking the ratio of 'variation' to mean. `cv=sd(x)/mean(x)`. 

This becomes even more apparent if we compute the CV and mean over replicates within sample groups (Time).

```{r,fig.height=5,fig.width=5,block.title=TRUE}
dx1 <- data.frame(t0=apply(cd[,1:3],1,cva),t2=apply(cd[,4:6],1,cva),
            t6=apply(cd[,7:9],1,cva),t24=apply(cd[,10:12],1,cva))
dx1$gene <- rownames(dx1)
dx1 <- tidyr::gather(dx1,key=sample,value=cv,-gene)
rownames(dx1) <- paste0(dx1$gene,"-",dx1$sample)

dx2 <- data.frame(t0=apply(cd[,1:3],1,mean),t2=apply(cd[,4:6],1,mean),
            t6=apply(cd[,7:9],1,mean),t24=apply(cd[,10:12],1,mean))
dx2$gene <- rownames(dx2)
dx2 <- tidyr::gather(dx2,key=sample,value=mean,-gene)
rownames(dx2) <- paste0(dx2$gene,"-",dx2$sample)

dx3 <- merge(dx1,dx2,by=0)

ggplot(dx3,aes(x=log10(mean+1),y=cv))+
  geom_point(alpha=0.2)+
  geom_smooth()+
  facet_wrap(~sample.x)+
  labs(x=expression('Log'[10]~'Mean counts'),y="Coefficient of variation")+
  theme_bw()
```

We find that CV strongly declines with increasing counts. Genes with low counts show higher dispersion. For the sake of completeness, we can also plot the relationship between CV and variance for the same sample groups.

```{r,fig.height=5,fig.width=5,block.title=TRUE}
dx1 <- data.frame(t0=apply(cd[,1:3],1,cva),t2=apply(cd[,4:6],1,cva),
            t6=apply(cd[,7:9],1,cva),t24=apply(cd[,10:12],1,cva))
dx1$gene <- rownames(dx1)
dx1 <- tidyr::gather(dx1,key=sample,value=cv,-gene)
rownames(dx1) <- paste0(dx1$gene,"-",dx1$sample)

dx2 <- data.frame(t0=apply(cd[,1:3],1,var),t2=apply(cd[,4:6],1,var),
            t6=apply(cd[,7:9],1,var),t24=apply(cd[,10:12],1,var))
dx2$gene <- rownames(dx2)
dx2 <- tidyr::gather(dx2,key=sample,value=var,-gene)
rownames(dx2) <- paste0(dx2$gene,"-",dx2$sample)

dx3 <- merge(dx1,dx2,by=0)

ggplot(dx3,aes(x=log10(var+1),y=cv))+
  geom_point(alpha=0.2)+
  geom_smooth()+
  facet_wrap(~sample.x)+
  labs(x=expression('Log'[10]~'Variance'),y="Coefficient of variation")+
  theme_bw()
```

</div>
</div>
</div>

DESeq2 computes it's own version of dispersion in a more robust manner taking into account low count values. The DESeq2 dispersion estimates are inversely related to the mean and directly related to variance. The dispersion estimate is a good measure of the variation in gene expression for a certain mean value.

Now, the variance or dispersion estimate for genes with low counts is unrealiable when there are too few replicates. To overcome this, DESeq2 borrows information from across other genes. DESeq2 assumes that genes with similar expression levels have similar dispersion values. Dispersion estimates are computed for each gene separately using maximum likelihood estimate. A curve is fitted to these gene-wise dispersion estimates. The gene-wise estimates are then 'shrunk' to the fitted curve.

Gene-wide dispersions, fitted curve and shrinkage can be visualised using the `plotDispEsts()` function.
 
```{r,fig.height=5.5,fig.width=5,block.title=TRUE}
d <- DESeq2::estimateDispersions(d)
plotDispEsts(d)
```

The black points denote the maximum likelihood dispersion estimate for each gene. The red curve denote the fitted curve. The blue points denote the new gene dispersion estimates after shrunk towards the curve. The circled blue points denote estimates that are not shrunk as they are too far away from the curve. This shrinkage method is important to reduce false positives in DGE analysis involving too few replicates.

<i class='fas fa-lightbulb'></i> It is a good idea to visually check the dispersion shrinkage plot to verify that the modelling works for your dataset.

## Testing

<div class="optional">
<b>Optional</b>

For details on over-dispersion, click below.

<p>
<button class="btn btn-sm btn-primary btn-collapse btn-collapse-optional collapsed type="button" data-toggle="collapse" data-target="#dge-testing" aria-expanded="false" aria-controls="dge-testing">
</button>
</p>
<div class="collapse" id="dge-testing">
<div class="card card-body">

We can go back to our mean-variance plot and add a smoothed red line.

```{r,fig.height=4.5,fig.width=4.5,block.title=TRUE}
dm <- apply(cd,1,mean)
dv <- apply(cd,1,var)

ggplot(data.frame(mean=log10(dm+1),var=log10(dv+1)),
       aes(mean,var))+
  geom_point(alpha=0.2)+
  geom_smooth(method="lm")+
  geom_smooth(colour="red")+
  labs(x=expression('Log'[10]~'Mean counts'),y="Log10 Variance")+
  theme_bw()
```

We can observe that the variance is larger than the mean. This is called overdispersion. Overdispersion is the reason which RNA-Seq data is modelled as negative-binomial distribution rather than poisson distribution. Poisson distribution has a mean = variance relationship, while negative-binomial distribution has a variance > mean relationship.

</div>
</div>
</div>

The last step in the DESeq2 workflow is fitting the Negative Binomial model for each gene and performing differential expression testing. This is based on the log fold change values computed on the corrected count estimates between groups.

`logFC = log2 (corrected counts group A / corrected counts group B)`

The most commonly used testing for comparing two groups in DESeq2 is the Walds's test. The null hypothesis is that the groups are not different and `logFC=0`. The list of contrasts can be seen using `resultsNames()`. Then we can pick our comparisons of interest.

```{r,block.title=TRUE}
dg <- nbinomWaldTest(d)
resultsNames(dg)
```

And we can get the result tables for the three different comparisons. The summary of the result object shows the number of genes that are differentially expressed with positive or negative fold-change and outliers.

```{r,block.title=TRUE}
res1 <- results(dg,name="Time_t2_vs_t0",alpha=0.05)
summary(res1)
res2 <- results(dg,name="Time_t24_vs_t0",alpha=0.05)
summary(res2)
res3 <- results(dg,name="Time_t6_vs_t0",alpha=0.05)
summary(res3)
```

The `results()` function has many useful arguments. One can set a threshold on the logFC values using `lfcThreshold`. By default, no filtering is performed based on logFC values. Outliers are detected and p-values are set to NA automatically using `cooksCutoff`. `independentFiltering` remove genes with low counts.

```{r,block.title=TRUE}
head(res1)
```

The results table contains mean expression value (baseMean), log2 fold change (log2FoldChange), log2 fold change standard error (lfcSE), wald test statistic (stat), wald test p-value (pvalue) and BH adjusted p-value (padj) for each gene.

<i class='fas fa-lightbulb'></i>  Note that the results object is a `DESeqResults` class object and not a data.frame. It can be converted to a data.frame using `as.data.frame()` for exporting to a file.

We can filter the results table as needed.

```{r,block.title=TRUE}
# all genes
nrow(as.data.frame(res1))
# only genes with padj <0.05
nrow(filter(as.data.frame(res1),padj<0.05))
# only genes with padj <0.05 and an absolute fold change >2
nrow(filter(as.data.frame(res1),padj<0.05,abs(log2FoldChange)>2))
```

# Visualisation

In this section, we can explore some useful visualisation of the differential gene expression output.

## MA plot

The MA plot shows mean expression vs log fold change for all genes. The `plotMA()` function from DESeq2 takes a results object as input. Differentially expressed genes are marked in red.

```{r,fig.height=5.5,fig.width=5,block.title=TRUE}
DESeq2::plotMA(res1)
```

## Volcano plot

A volcano plot is similar to the MA plot. It plots log fold change vs adjusted p-values.

```{r,fig.height=5,fig.width=5,block.title=TRUE}
ggplot()+
  geom_point(data=as.data.frame(res1),aes(x=log2FoldChange,y=-log10(padj)),col="grey80",alpha=0.5)+
  geom_point(data=filter(as.data.frame(res1),padj<0.05),aes(x=log2FoldChange,y=-log10(padj)),col="red",alpha=0.7)+
  geom_hline(aes(yintercept=-log10(0.05)),alpha=0.5)+
  theme_bw()
```

X axis denotes log fold change and the y axis denotes -log10 adjusted p-value. The adjusted p-value is transformed so that the smallest p-values appears at the top. The horizontal grey line denotes the significance threshold line. All genes above this line (coloured red as well) are considered significant.

## Counts plot

It can be a good idea to manually verify some of these genes by plotting out it's actual read count values. We can use the function `plotCounts()` to visualise the data points for a gene of interest. Below, we see the counts before and after normalisation.

```{r,fig.height=5,fig.width=5,block.title=TRUE}
plotCounts(d,gene=rownames(res1)[1],intgroup="Time",normalized=F)
plotCounts(d,gene=rownames(res1)[1],intgroup="Time",normalized=T)
```

# Session info

```{r,echo=FALSE}
sessionInfo()
```
